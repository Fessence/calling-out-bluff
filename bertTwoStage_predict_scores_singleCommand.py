import xgboost as xgb
import os
import numpy as np
import yaml
import json
import pandas as pd
from util import *
import csv
# from predict import *
dataset_score_range = {
    1: (2, 12, 1783),
    2: (1, 6, 1800),
    3: (0, 3, 1726),
    4: (0, 3, 1772),
    5: (0, 4, 1805),
    6: (0, 4, 1800),
    7: (0, 30, 1569),
    8: (0, 60, 723)
}

import sys 
argslist = list(sys.argv)
print(argslist)

prompt_id = argslist[1]
adv_file = argslist[2]
print("PromptID is: ", prompt_id)
print("Adversarial File: ", adv_file)

with open("config/sys_conf.yaml", encoding="utf-8") as conf_reader:
    sys_conf = yaml.load(conf_reader.read())
    sys_conf["bsp_output_dir"] = "basic_score_prompt"+prompt_id
    sys_conf["csp_output_dir"] = "coherence_score_prompt"+prompt_id
    sys_conf["psp_output_dir"] = "prompt_score_prompt"+prompt_id
    sys_conf["osp_output_dir"] = "overall_score_prompt"+prompt_id
#     print(sys_conf)
with open("config/train_conf.json", "r") as cr:
    train_conf = json.load(cr)
    train_conf["prompt_id"] = int(prompt_id)
with open("config/doc_conf.json", "r") as cr:
    doc_conf = json.load(cr)    

saved_model_dir = "overall_score_prompt" + prompt_id
print(saved_model_dir)
tfrecord_file_path = os.path.join(sys_conf["data_dir"], "asap_dataset_prompt.tfrecord")

a = 1
if a == 1:
    testcases_name = adv_file[:-4]
    xgboost_adv_file_path = "feature_files/asap_xgboost_"+testcases_name+".npz"
    def read_asap_dataset():
        asap_csv_file_path = os.path.join(sys_conf["data_dir"], "prompt"+prompt_id+".csv")
        print("ASAP_CSV_FILE_PATH", asap_csv_file_path)
        if not os.path.exists(asap_csv_file_path):
            raise ValueError("asap_file_path is invalid.")
        asap_dataset = pd.read_csv(asap_csv_file_path, encoding='utf-8')
        adv_dataset = pd.read_csv(adv_file, encoding='utf-8')
        adv_dataset.columns = ['essay']
        adv_dataset.insert(0, 'ID', range(1, 1 + len(adv_dataset)))
        if (adv_dataset.iloc[0]["essay"] == "text"):
            adv_dataset = pd.read_csv(adv_file, encoding='utf-8')
            adv_dataset.insert(0, 'ID', range(1, 1 + len(adv_dataset)))
        adv_dataset = adv_dataset[["ID", "essay"]]
        articles_id = list(adv_dataset["ID"])
        articles_set = list(asap_dataset["essay_set"])
        domain1_score = asap_dataset["domain1_score"]
        handmark_scores = dict(zip(articles_id, domain1_score))
        set_ids = {
            1: [],
            2: [],
            3: [],
            4: [],
            5: [],
            6: [],
            7: [],
            8: []
        }
        for i in range(len(articles_id)):
            set_ids[articles_set[i]].append(articles_id[i])

        return articles_id, articles_set, domain1_score

    def read_asap_dataset_correspond():
        asap_csv_file_path = os.path.join(sys_conf["data_dir"], "prompt"+prompt_id+".csv")
        if not os.path.exists(asap_csv_file_path):
            raise ValueError("asap_file_path is invalid.")
        asap_dataset = pd.read_csv(asap_csv_file_path, encoding='utf-8')
        adv_dataset = pd.read_csv(adv_file, encoding='utf-8', header=None)
        adv_dataset.insert(0, 'ID', range(1, 1 + len(adv_dataset)))
        articles_id = list(adv_dataset["ID"])
        articles_set = list(asap_dataset["essay_set"])
        domain1_score = asap_dataset["domain1_score"]
        handmark_scores = dict(zip(articles_id, domain1_score))
        set_ids = {
            1: [],
            2: [],
            3: [],
            4: [],
            5: [],
            6: [],
            7: [],
            8: []
        }
        for i in range(len(articles_id)):
            set_ids[articles_set[i]].append(articles_id[i])

        return articles_id, articles_set, set_ids, handmark_scores

    def generate_xgboost_train_set(articles_id, articles_set, domain1_scores, train_set_gec_result_path, train_set_saved_path):
        """Generate xgboost training data set based on the result of the training set gec

        Args:
            articles_id: list of training set article ids
            articles_set: list of training set articles
            domain1_scores: the manually labeled scores of the articles in the training set, because the asap dataset calls this score domain1_scores
            train_set_gec_result_path: The path of the result file generated by the gec engine in the training set article, the file format is a line corresponding to the gec result of an article.
            train_set_saved_path: save as npz file type, save path of npz file

        Returns: None.

        """
        dataset_gec_path = train_set_gec_result_path
        dataset_xgboost_train_file = train_set_saved_path

        # normalized_scores
        handmark_scores = dict(zip(articles_id, domain1_scores))

        # normalized_orgin_scores
        handmark_normalized_scores = {}
        for key, value in handmark_scores.items():
            article_set_id = articles_set[articles_id.index(key)]
            min_value = dataset_score_range[article_set_id][0]
            max_value = dataset_score_range[article_set_id][1]
            normalize_value = (value - min_value) / (max_value - min_value)
            handmark_normalized_scores[key] = normalize_value

        features = {}

        count = 0
        with open(dataset_gec_path, encoding="ISO-8859-1") as fr:
            for line in fr:
                count +=1
                id = count
                gec_output = line.strip()
                features[id] = Document(gec_output).features
        np.savez(dataset_xgboost_train_file, features=features)
        print("Done")

    articles_id, articles_set, domain1_score = read_asap_dataset()
    generate_xgboost_train_set(articles_id, articles_set, domain1_score, adv_file, xgboost_adv_file_path)


    #Load Saved model
    xgb_rg = xgb.XGBRegressor(n_estimators=5000, learning_rate=0.001, max_depth=6, gamma=0.05,
                                      objective="reg:logistic")
    xgb_rg.load_model(os.path.join(saved_model_dir, "osp3.xgboost"))

    #Score Range
    max_value = dataset_score_range[int(prompt_id)][1]
    min_value = dataset_score_range[int(prompt_id)][0]
    print("MAX AND MIN", max_value, min_value)

    #Load feature file of adversary testcase
    features_adv = np.load(xgboost_adv_file_path, allow_pickle=True)["features"][()]

    #Generate correspond_adv_id_set
    articles_id, articles_set, set_ids, handmark_scores = read_asap_dataset_correspond()
    permutation_adv_ids = np.random.permutation(set_ids[train_conf["prompt_id"]])
#     print(permutation_adv_ids)
    correspond_adv_id_set = permutation_adv_ids

    test_features_adv = []
    for i in correspond_adv_id_set:
        if (i in features_adv.keys() or (i - 100000) in features_adv.keys()) or i in basic_scores and i in promp_scores and i in coher_scores:
            temp_i = i
            if temp_i > 100000:
                temp_i = temp_i - 100000
            temp_features_adv = features_adv[temp_i]
            test_features_adv.append(temp_features_adv)
    
    test_features_adv = np.array(test_features_adv)
    pred_scores = xgb_rg.predict(test_features_adv)
    test_predict_scores = []
    for i in range(len(correspond_adv_id_set)):
        overall_score = pred_scores[i] * (max_value - min_value) + min_value
        test_predict_scores.append(overall_score)

    file = open("../../bertTwoStage"+testcases_name+"_upscaled.csv", 'w+', newline ='') 

    # writing the data into the file 
    with file:     
        write = csv.writer(file) 
        write.writerows(map(lambda x: [x], test_predict_scores))
    print("save to csv: ", testcases_name)
    print("File saved")